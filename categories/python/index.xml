<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Python on Johnny's Blog</title><link>https://lijohnny.com/categories/python/</link><description>Recent content in Python on Johnny's Blog</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Fri, 12 Mar 2021 21:42:22 -0800</lastBuildDate><atom:link href="https://lijohnny.com/categories/python/index.xml" rel="self" type="application/rss+xml"/><item><title>Identify Customer Segments</title><link>https://lijohnny.com/p/identify-customer-segments/</link><pubDate>Fri, 12 Mar 2021 21:42:22 -0800</pubDate><guid>https://lijohnny.com/p/identify-customer-segments/</guid><description>This is one of the Udacity Data Scientist Nanodegree Project. This project aims to identify segments of the population from the core customer base for a mail-order sales company in Germany. Therefore, these segments can then be used to direct marketing campaigns towards audiences with the highest expected rate of returns.
The techniques I used in this project include:
Data cleaning Encoding and processing mixed-type feature Feature Scaling and Dimensionality Reduction Clustering Performance improvement with OpenBLAS You can find the full analysis in my GitHub repo.</description></item><item><title>Donors Identification for CharityML</title><link>https://lijohnny.com/p/donors-identification-for-charityml/</link><pubDate>Thu, 30 May 2019 01:03:50 +0000</pubDate><guid>https://lijohnny.com/p/donors-identification-for-charityml/</guid><description>&lt;p>&lt;a class="link" href="https://lijohnny.com" target="_blank" rel="noopener"
>&lt;img src="https://img.shields.io/badge/Ask%20me-anything-1abc9c.svg" alt="" />&lt;/a> &lt;a class="link" href="https://www.python.org/" target="_blank" rel="noopener"
>&lt;img src="https://img.shields.io/badge/Made%20with-Python-1f425f.svg" alt="" />&lt;/a> &lt;a class="link" href="" >&lt;img src="https://img.shields.io/badge/Kaggle-Project-blue.svg" alt="" />&lt;/a>&lt;/p>
&lt;p>In this project, I built machine learning models that best identifies potential donors for CharityML(a fictitious charity organization) with data collected for the U.S. census. To find the best approach, I performed EDA, feature engineering, and building training and predicting pipeline to evaluate and optimize the performance between different machine learning models.&lt;/p>
&lt;p>The modified census dataset consists of approximately 32,000 data points, with each datapoint having 13 features. This dataset is a modified version of the dataset published in the paper &lt;em>&amp;ldquo;Scaling Up the Accuracy of Naive-Bayes Classifiers: a Decision-Tree Hybrid&amp;rdquo;,&lt;/em> by Ron Kohavi. You may find this paper &lt;a class="link" href="https://www.aaai.org/Papers/KDD/1996/KDD96-033.pdf" target="_blank" rel="noopener"
>online&lt;/a>, with the original dataset hosted on &lt;a class="link" href="https://archive.ics.uci.edu/ml/datasets/Census&amp;#43;Income" target="_blank" rel="noopener"
>UCI&lt;/a>.&lt;/p>
&lt;p>The model I have used:&lt;/p>
&lt;ul>
&lt;li>SGD Classifier&lt;/li>
&lt;li>AdaBoost&lt;/li>
&lt;li>Logistic Regression&lt;/li>
&lt;/ul></description></item><item><title>Automate Image Processing for My Blog</title><link>https://lijohnny.com/p/automate-image-processing-for-my-blog/</link><pubDate>Sat, 11 May 2019 22:28:30 +0000</pubDate><guid>https://lijohnny.com/p/automate-image-processing-for-my-blog/</guid><description>&lt;blockquote>
&lt;p>:warning:The old cript is &lt;code>DEPRECATED&lt;/code>. I switch to FastAPI, and updated the code &lt;a class="link" href="https://github.com/iamjohnnyli/blog-image-processing-automation" target="_blank" rel="noopener"
>here&lt;/a>. The old code is now in &lt;a class="link" href="https://github.com/iamjohnnyli/blog-image-processing-automation/tree/V1.0" target="_blank" rel="noopener"
>v1.0 Branch&lt;/a>.&lt;/p>
&lt;/blockquote>
&lt;p>As you can see, my blog contains cover images. Every time I write an article I need to upload a cover image to the image server. However, the process is complicated and trivial. I need to crop the image to a certain proportion and resize and compress the image to reduce the loading time. Moreover, to put the photographer&amp;rsquo;s name on the image, I need to use other software. Therefore, I create two python scripts to automate the process.&lt;/p></description></item><item><title>Spam Detection and Analysis (Part 1 - Parsing)</title><link>https://lijohnny.com/p/spam-detection-and-analysis-part-1-parsing/</link><pubDate>Fri, 19 Apr 2019 01:24:59 +0000</pubDate><guid>https://lijohnny.com/p/spam-detection-and-analysis-part-1-parsing/</guid><description>Spam is still a common attack method. Most of the email services have spam filters that can help us block and filter out most of the emails with commercial, fraudulent and malicious content. The purpose of the project is to explore and analyze the email header to identify the features that can tell us which emails are malicious.
Get Email Header information First thing we need to do is the get the data.</description></item><item><title>Craigslist Vacation House Data Crawling</title><link>https://lijohnny.com/p/craigslist-vacation-house-data-crawling/</link><pubDate>Tue, 12 Feb 2019 01:13:34 -0800</pubDate><guid>https://lijohnny.com/p/craigslist-vacation-house-data-crawling/</guid><description>&lt;p>In this &lt;a class="link" href="https://github.com/iamjohnnyli/web-crawler-tutorial/tree/master/scrapy_craigslist" target="_blank" rel="noopener"
>tutorial&lt;/a> I use &lt;a class="link" href="https://scrapy.org/" target="_blank" rel="noopener"
>Scrapy&lt;/a> to collect data from Craigslist.com. Specifically, the data under craigslist.org/Seattle/housing/vacation rentals. You can find the page under the link: &lt;a class="link" href="https://seattle.craigslist.org/d/vacation%e2%80%90rentals/search/vac" target="_blank" rel="noopener"
>https://seattle.craigslist.org/d/vacationâ€rentals/search/vac&lt;/a>&lt;/p></description></item></channel></rss>