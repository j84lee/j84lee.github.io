<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="The is a tutorial of using Scrayp to get collect data from Craigslist.com."><title>Craigslist Vacation House Data Crawling</title><link rel=canonical href=https://lijohnny.com/p/craigslist-vacation-house-data-crawling/><link rel=stylesheet href=/scss/style.min.css><meta property="og:title" content="Craigslist Vacation House Data Crawling"><meta property="og:description" content="The is a tutorial of using Scrayp to get collect data from Craigslist.com."><meta property="og:url" content="https://lijohnny.com/p/craigslist-vacation-house-data-crawling/"><meta property="og:site_name" content="Johnny's"><meta property="og:type" content="article"><meta property="article:section" content="Post"><meta property="article:tag" content="Python"><meta property="article:tag" content="Crawling"><meta property="article:tag" content="Scrapy"><meta property="article:tag" content="Tutorial"><meta property="article:tag" content="HTML"><meta property="article:published_time" content="2019-02-12T01:13:34-08:00"><meta property="article:modified_time" content="2019-02-12T01:13:34-08:00"><meta property="og:image" content="https://i.loli.net/2019/05/12/5cd7d789264a1.jpg"><meta name=twitter:site content="IAmJohnnyLi"><meta name=twitter:title content="Craigslist Vacation House Data Crawling"><meta name=twitter:description content="The is a tutorial of using Scrayp to get collect data from Craigslist.com."><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://i.loli.net/2019/05/12/5cd7d789264a1.jpg"><script type=application/javascript>var doNotTrack=!1;doNotTrack||(window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga('create','UA-136585559-1','auto'),ga('send','pageview'))</script><script async src=https://www.google-analytics.com/analytics.js></script></head><body><script>(function(){const a='StackColorScheme';localStorage.getItem(a)||localStorage.setItem(a,"auto")})()</script><script>(function(){const b='StackColorScheme',a=localStorage.getItem(b),c=window.matchMedia('(prefers-color-scheme: dark)').matches===!0;a=='dark'||a==='auto'&&c?document.body.dataset.scheme='dark':document.body.dataset.scheme='light'})()</script><div class="container main-container flex on-phone--column extended article-page with-toolbar"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label="Toggle Menu">
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header class=site-info><figure class=site-avatar><img src=/img/wechatjohnny_hu8fd990fde31e9d807c195376b9ec1613_42994_300x0_resize_q75_box.jpg width=300 height=300 class=site-logo loading=lazy alt=Avatar>
<span class=emoji>üññ</span></figure><h1 class=site-name><a href=https://lijohnny.com>Johnny's</a></h1><h2 class=site-description>Data Scientist | Program Manager</h2></header><ol class=menu id=main-menu><li><a href=/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg><span>Home</span></a></li><li><a href=/about><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-user" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="7" r="4"/><path d="M6 21v-2a4 4 0 014-4h4a4 4 0 014 4v2"/></svg><span>About</span></a></li><li><a href=/archives><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><rect x="3" y="4" width="18" height="4" rx="2"/><path d="M5 8v10a2 2 0 002 2h10a2 2 0 002-2V8"/><line x1="10" y1="12" x2="14" y2="12"/></svg><span>Archives</span></a></li><li><a href=/search><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg><span>Search</span></a></li><li id=dark-mode-toggle><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg><span>Dark Mode</span></li></ol></aside><main class="main full-width"><div id=article-toolbar><a href=https://lijohnny.com class=back-home><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-chevron-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="15 6 9 12 15 18"/></svg><span>Back</span></a></div><article class="has-image main-article"><header class=article-header><div class=article-image><a href=/p/craigslist-vacation-house-data-crawling/><img src=https://i.loli.net/2019/05/12/5cd7d789264a1.jpg loading=lazy alt="Featured image of post Craigslist Vacation House Data Crawling"></a></div><div class=article-details><header class=article-category><a href=/categories/data/ style=background-color:#2a9d8f;color:#fff>Data</a>
<a href=/categories/python/ style=background-color:#2a9d8f;color:#fff>Python</a></header><h2 class=article-title><a href=/p/craigslist-vacation-house-data-crawling/>Craigslist Vacation House Data Crawling</a></h2><h3 class=article-subtitle>The is a tutorial of using Scrayp to get collect data from Craigslist.com.</h3><footer class=article-time><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg><time class=article-time--published>Feb 12, 2019</time></footer></div></header><section class=article-content><p>In this <a class=link href=https://github.com/iamjohnnyli/web-crawler-tutorial/tree/master/scrapy_craigslist target=_blank rel=noopener>tutorial</a> I use <a class=link href=https://scrapy.org/ target=_blank rel=noopener>Scrapy</a> to collect data from Craigslist.com. Specifically, the data under craigslist.org/Seattle/housing/vacation rentals. You can find the page under the link: <a class=link href=https://seattle.craigslist.org/d/vacation%e2%80%90rentals/search/vac target=_blank rel=noopener>https://seattle.craigslist.org/d/vacation‚Äêrentals/search/vac</a></p><p>In the example, I collected following information:</p><ol><li>Title</li><li>Posted Date</li><li>Rental Price</li><li>Number of bedrooms</li><li>Neighborhood</li><li>Description</li></ol><blockquote><p>For more information or the code, please go to my <a class=link href=https://github.com/iamjohnnyli/web-crawler-tutorial/tree/master/scrapy_craigslist target=_blank rel=noopener>github page</a>.</p></blockquote><h2 id=preparation>PREPARATION</h2><h3 id=installation>INSTALLATION</h3><p>You can install scrapy through <code>pip install</code> command:</p><div class=highlight><pre class=chroma><code class=language-bash data-lang=bash>$ pip install scrapy
</code></pre></div><p>or use <code>conda install</code> command:</p><div class=highlight><pre class=chroma><code class=language-bash data-lang=bash>$ conda install scrapy
</code></pre></div><h3 id=creat-project>CREAT PROJECT</h3><p>Before we start coding, we can use <code>scrapy startproject</code> command to quickly create a project.
In terminal or CMD, navigate to your desired folder and execute following command:</p><div class=highlight><pre class=chroma><code class=language-bash data-lang=bash>$ scrapy startproject scrapy_craigslist
</code></pre></div><p>Here <em>scrapy_craigslist</em> is the name of the project.</p><p>After that, we can use <code>genspider</code> command to create a Scrapy Spider. Here, we name it vacation_rentals and designated a URL. We user craiglist.org Seattle vacation house list page as an example.</p><div class=highlight><pre class=chroma><code class=language-bash data-lang=bash>$ scrapy genspider vacation_rentals seattle.craigslist.org/d/vacation‚Äêrentals/search/vac
</code></pre></div><p>This will create a directory with the following structure:</p><pre><code>‚îÄ‚îÄ‚îÄ scrapy_craigslist
    ‚îú‚îÄ‚îÄ __init__.py
    ‚îú‚îÄ‚îÄ __pycache__
    ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ __init__.cpython-36.pyc
    ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ settings.cpython-36.pyc
    ‚îú‚îÄ‚îÄ items.py
    ‚îú‚îÄ‚îÄ middlewares.py
    ‚îú‚îÄ‚îÄ pipelines.py
    ‚îú‚îÄ‚îÄ settings.py
    ‚îî‚îÄ‚îÄ spiders
        ‚îú‚îÄ‚îÄ __init__.py
        ‚îú‚îÄ‚îÄ __pycache__
        ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ __init__.cpython-36.pyc
        ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ vacation_rentals.cpython-36.pyc
        ‚îî‚îÄ‚îÄ vacation_rentals.py
</code></pre><h2 id=editing>EDITING</h2><p>Navigate to the spiders folder and open the spider py file in your favorite editor.
There are some pre written code, but you need to make sure that <code>allowed_domains</code> and <code>start_urls</code> are in the right form.</p><div class=highlight><pre class=chroma><code class=language-python data-lang=python><span class=kn>import</span> <span class=nn>scrapy</span>

<span class=k>class</span> <span class=nc>CarSpider</span><span class=p>(</span><span class=n>scrapy</span><span class=o>.</span><span class=n>Spider</span><span class=p>):</span>
    <span class=n>name</span> <span class=o>=</span> <span class=s1>&#39;car&#39;</span>
    <span class=n>allowed_domains</span> <span class=o>=</span> <span class=p>[</span><span class=s1>&#39;craigslist.org&#39;</span><span class=p>]</span>
    <span class=n>start_urls</span> <span class=o>=</span> <span class=p>[</span><span class=s1>&#39;https://seattle.craigslist.org/d/vacation‚Äêrentals/search/vac/&#39;</span><span class=p>]</span>

    <span class=k>def</span> <span class=nf>parse</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>response</span><span class=p>):</span>
        <span class=k>pass</span>

</code></pre></div><p>Let&rsquo;s write our own code under <code>def parse(self, response):</code>. You can check the code <a class=link href=https://github.com/iamjohnnyli/web-crawler-tutorial/blob/master/scrapy_craigslist/scrapy_craigslist/spiders/vacation_rentals.py target=_blank rel=noopener>here</a>.</p><div class=highlight><pre class=chroma><code class=language-python data-lang=python><span class=c1># -*- coding: utf-8 -*-</span>
<span class=kn>import</span> <span class=nn>scrapy</span>
<span class=kn>from</span> <span class=nn>scrapy</span> <span class=kn>import</span> <span class=n>Request</span>
<span class=kn>import</span> <span class=nn>re</span>


<span class=k>class</span> <span class=nc>VacationRentalsSpider</span><span class=p>(</span><span class=n>scrapy</span><span class=o>.</span><span class=n>Spider</span><span class=p>):</span>
    <span class=n>name</span> <span class=o>=</span> <span class=s1>&#39;vacation_rentals&#39;</span>
    <span class=n>allowed_domains</span> <span class=o>=</span> <span class=p>[</span><span class=s1>&#39;craigslist.org&#39;</span><span class=p>]</span>
    <span class=n>start_urls</span> <span class=o>=</span> <span class=p>[</span><span class=s1>&#39;http://seattle.craigslist.org/d/vacation‚Äêrentals/search/vac/&#39;</span><span class=p>]</span>

    <span class=k>def</span> <span class=nf>parse</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>response</span><span class=p>):</span>
        <span class=c1># Extract all wrapper for each list item between &lt;p class=&#34;result-info&#34;&gt;&lt;/p&gt;</span>
        <span class=n>vacs</span> <span class=o>=</span> <span class=n>response</span><span class=o>.</span><span class=n>xpath</span><span class=p>(</span><span class=s1>&#39;//p[@class=&#34;result-info&#34;]&#39;</span><span class=p>)</span>
        <span class=c1># Get next page button URL &lt;a href=&#34;/search/vac?s=120&#34; class=&#34;button next&#34; title=&#34;next page&#34;&gt;next &amp;gt; &lt;/a&gt;</span>
        <span class=n>next_rel_url</span> <span class=o>=</span> <span class=n>response</span><span class=o>.</span><span class=n>xpath</span><span class=p>(</span><span class=s1>&#39;//a[@class=&#34;button next&#34;]/@href&#39;</span><span class=p>)</span><span class=o>.</span><span class=n>extract_first</span><span class=p>()</span>
        <span class=c1># Get full address.</span>
        <span class=n>next_url</span> <span class=o>=</span> <span class=n>response</span><span class=o>.</span><span class=n>urljoin</span><span class=p>(</span><span class=n>next_rel_url</span><span class=p>)</span>
        <span class=c1># Go through all the pages.</span>
        <span class=k>yield</span> <span class=n>Request</span><span class=p>(</span><span class=n>next_url</span><span class=p>,</span> <span class=n>callback</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>parse</span><span class=p>)</span>

        <span class=c1># Loop each item to extract title, posted date, rental price, number of bedrooms, and neighborhood</span>
        <span class=k>for</span> <span class=n>vac</span> <span class=ow>in</span> <span class=n>vacs</span><span class=p>:</span>
            <span class=c1># Get title from &lt;a&gt;&lt;/a&gt; tag.</span>
            <span class=n>title</span> <span class=o>=</span> <span class=n>vac</span><span class=o>.</span><span class=n>xpath</span><span class=p>(</span><span class=s1>&#39;a/text()&#39;</span><span class=p>)</span><span class=o>.</span><span class=n>extract_first</span><span class=p>()</span>
            <span class=c1># Get posted date from &lt;time class=&#34;result-date&#34; datetime=&#34;2019-03-06 18:34&#34; title=&#34;Wed 06 Mar 06:34:28 PM&#34;&gt;Mar  6&lt;/time&gt; block. Use @datetime for attribute datetime.</span>
            <span class=n>pdate</span> <span class=o>=</span> <span class=n>vac</span><span class=o>.</span><span class=n>xpath</span><span class=p>(</span><span class=s1>&#39;time/@datetime&#39;</span><span class=p>)</span><span class=o>.</span><span class=n>extract_first</span><span class=p>()</span><span class=o>.</span><span class=n>split</span><span class=p>()[</span><span class=mi>0</span><span class=p>]</span>
            <span class=c1># Get rental price form &lt;span class=&#34;result-price&#34;&gt;$84&lt;/span&gt;</span>
            <span class=n>rprice</span> <span class=o>=</span> <span class=n>vac</span><span class=o>.</span><span class=n>xpath</span><span class=p>(</span><span class=s1>&#39;span/span[@class=&#34;result-price&#34;]/text()&#39;</span><span class=p>)</span><span class=o>.</span><span class=n>extract_first</span><span class=p>()</span>
            <span class=c1># Get Number of bedrooms from &lt;span class=&#34;housing&#34;&gt;2br - 760ft&lt;sup&gt;2&lt;/sup&gt; - &lt;/span&gt; and clean up the extra</span>
            <span class=n>nbedroom</span> <span class=o>=</span> <span class=nb>str</span><span class=p>(</span><span class=n>vac</span><span class=o>.</span><span class=n>xpath</span><span class=p>(</span><span class=s1>&#39;span/span[@class=&#34;housing&#34;]/text()&#39;</span><span class=p>)</span><span class=o>.</span><span class=n>extract_first</span><span class=p>())</span><span class=o>.</span><span class=n>split</span><span class=p>(</span><span class=s1>&#39;-&#39;</span><span class=p>)[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>strip</span><span class=p>()</span>
            <span class=c1># Get Neighborhood from &lt;span class=&#34;result-hood&#34;&gt; (*** - *****)&lt;/span&gt;</span>
            <span class=n>hood</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=s1>&#39;[()]&#39;</span><span class=p>,</span> <span class=s1>&#39;&#39;</span><span class=p>,</span> <span class=nb>str</span><span class=p>(</span><span class=n>vac</span><span class=o>.</span><span class=n>xpath</span><span class=p>(</span><span class=s1>&#39;span/span[@class=&#34;result-hood&#34;]/text()&#39;</span><span class=p>)</span><span class=o>.</span><span class=n>extract_first</span><span class=p>()))</span><span class=o>.</span><span class=n>strip</span><span class=p>()</span>
            <span class=c1># Get the address of description page of each vacation house.</span>
            <span class=n>vacaddress</span> <span class=o>=</span> <span class=n>vac</span><span class=o>.</span><span class=n>xpath</span><span class=p>(</span><span class=s1>&#39;a/@href&#39;</span><span class=p>)</span><span class=o>.</span><span class=n>extract_first</span><span class=p>()</span>
            <span class=c1># We needed open the URL of each house and scrape the house description, while passing the meta to parse_page function.</span>
            <span class=k>yield</span> <span class=n>Request</span><span class=p>(</span><span class=n>vacaddress</span><span class=p>,</span> <span class=n>callback</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>parse_page</span><span class=p>,</span> <span class=n>meta</span><span class=o>=</span><span class=p>{</span><span class=s1>&#39;URL&#39;</span><span class=p>:</span> <span class=n>vacaddress</span><span class=p>,</span> <span class=s1>&#39;Title&#39;</span><span class=p>:</span> <span class=n>title</span><span class=p>,</span> <span class=s1>&#39;Posted Date&#39;</span><span class=p>:</span><span class=n>pdate</span><span class=p>,</span><span class=s2>&#34;Rental Price&#34;</span><span class=p>:</span><span class=n>rprice</span><span class=p>,</span><span class=s2>&#34;Number of bedrooms&#34;</span><span class=p>:</span><span class=n>nbedroom</span><span class=p>,</span> <span class=s2>&#34;Neighborhood&#34;</span><span class=p>:</span><span class=n>hood</span><span class=p>})</span>

    <span class=c1># Extract description page of the vacation house.</span>
    <span class=k>def</span> <span class=nf>parse_page</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>response</span><span class=p>):</span>
        <span class=c1># Pass the variables</span>
        <span class=n>url</span> <span class=o>=</span> <span class=n>response</span><span class=o>.</span><span class=n>meta</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s1>&#39;URL&#39;</span><span class=p>)</span>
        <span class=n>title</span> <span class=o>=</span> <span class=n>response</span><span class=o>.</span><span class=n>meta</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s1>&#39;Title&#39;</span><span class=p>)</span>
        <span class=n>pdate</span> <span class=o>=</span> <span class=n>response</span><span class=o>.</span><span class=n>meta</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s1>&#39;Posted Date&#39;</span><span class=p>)</span>
        <span class=n>rprice</span> <span class=o>=</span> <span class=n>response</span><span class=o>.</span><span class=n>meta</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s1>&#39;Rental Price&#39;</span><span class=p>)</span>
        <span class=n>nbedroom</span> <span class=o>=</span> <span class=n>response</span><span class=o>.</span><span class=n>meta</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s1>&#39;Number of bedrooms&#39;</span><span class=p>)</span>
        <span class=n>hood</span> <span class=o>=</span> <span class=n>response</span><span class=o>.</span><span class=n>meta</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s1>&#39;Neighborhood&#39;</span><span class=p>)</span>
        <span class=c1># Get the description.</span>
        <span class=n>description</span> <span class=o>=</span> <span class=s2>&#34;&#34;</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>line</span> <span class=k>for</span> <span class=n>line</span> <span class=ow>in</span> <span class=n>response</span><span class=o>.</span><span class=n>xpath</span><span class=p>(</span><span class=s1>&#39;//*[@id=&#34;postingbody&#34;]/text()&#39;</span><span class=p>)</span><span class=o>.</span><span class=n>extract</span><span class=p>())</span>

        <span class=k>yield</span><span class=p>{</span><span class=s1>&#39;Title&#39;</span><span class=p>:</span> <span class=n>title</span><span class=p>,</span> <span class=s1>&#39;Posted Date&#39;</span><span class=p>:</span><span class=n>pdate</span><span class=p>,</span><span class=s2>&#34;Rental Price&#34;</span><span class=p>:</span><span class=n>rprice</span><span class=p>,</span><span class=s2>&#34;Number of bedrooms&#34;</span><span class=p>:</span><span class=n>nbedroom</span><span class=p>,</span> <span class=s2>&#34;Neighborhood&#34;</span><span class=p>:</span><span class=n>hood</span><span class=p>,</span><span class=s1>&#39;Description&#39;</span><span class=p>:</span><span class=n>description</span><span class=p>}</span>

</code></pre></div><h3 id=run-spider>RUN SPIDER</h3><p>To put our spider to work, run <code>crawl</code> command in terminal or CMD:</p><div class=highlight><pre class=chroma><code class=language-bash data-lang=bash>$ scrapy crawl vacation_rentals -o result-titles.csv
</code></pre></div><p><code>-o</code> means out put data into file. <code>result-titles.csv</code> is the files' name.</p></section><footer class=article-footer><section class=article-tags><a href=/tags/python/>Python</a>
<a href=/tags/crawling/>Crawling</a>
<a href=/tags/scrapy/>Scrapy</a>
<a href=/tags/tutorial/>Tutorial</a>
<a href=/tags/html/>HTML</a></section><section class=article-copyright><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><path d="M14.5 9a3.5 4 0 100 6"/></svg><span>Licensed under CC BY-NC-SA 4.0</span></section></footer></article><aside class=related-contents--wrapper><h2 class=section-title>Related contents</h2><div class=related-contents><div class="flex article-list--tile"><article class=has-image><a href=/p/spam-detection-and-analysis-part-2-analysis-with-r/><div class=article-image><img src=https://i.loli.net/2019/05/10/5cd5051a0e1f9.png loading=lazy data-key data-hash=https://i.loli.net/2019/05/10/5cd5051a0e1f9.png></div><div class=article-details><h2 class=article-title>Spam Detection and Analysis (Part 2 - Analysis with R)</h2></div></a></article><article class=has-image><a href=/p/spam-detection-and-analysis-part-1-parsing/><div class=article-image><img src=https://i.loli.net/2019/05/10/5cd50420b955f.png loading=lazy data-key data-hash=https://i.loli.net/2019/05/10/5cd50420b955f.png></div><div class=article-details><h2 class=article-title>Spam Detection and Analysis (Part 1 - Parsing)</h2></div></a></article><article class=has-image><a href=/p/donors-identification-for-charityml/><div class=article-image><img src=https://i.loli.net/2019/05/30/5cef9192b167778174.jpg loading=lazy data-key data-hash=https://i.loli.net/2019/05/30/5cef9192b167778174.jpg></div><div class=article-details><h2 class=article-title>Donors Identification for CharityML</h2></div></a></article><article class=has-image><a href=/p/automate-image-processing-for-my-blog/><div class=article-image><img src=https://i.loli.net/2019/05/12/5cd7b069e734a.jpg loading=lazy data-key data-hash=https://i.loli.net/2019/05/12/5cd7b069e734a.jpg></div><div class=article-details><h2 class=article-title>Automate Image Processing for My Blog</h2></div></a></article><article class=has-image><a href=/p/how-to-build-consistent-development-environment-through-docker/><div class=article-image><img src=https://i.loli.net/2019/04/27/5cc38cc0066e1.jpg loading=lazy data-key data-hash=https://i.loli.net/2019/04/27/5cc38cc0066e1.jpg></div><div class=article-details><h2 class=article-title>How to Build Consistent Development Environment through Docker</h2></div></a></article></div></div></aside><div class=disqus-container><div id=disqus_thread></div><script type=application/javascript>var disqus_config=function(){};(function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById('disqus_thread').innerHTML='Disqus comments not available by default when the website is previewed locally.';return}var b=document,a=b.createElement('script');a.async=!0,a.src='//j84lee-github-io.disqus.com/embed.js',a.setAttribute('data-timestamp',+new Date),(b.head||b.body).appendChild(a)})()</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=https://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a></div><style>.disqus-container{background-color:var(--card-background);border-radius:var(--card-border-radius);box-shadow:var(--shadow-l1);padding:var(--card-padding)}</style><script>window.addEventListener('onColorSchemeChange',a=>{DISQUS&&DISQUS.reset({reload:!0})})</script><footer class=site-footer><section class=copyright>&copy;
2019 -
2021 Johnny's</section><section class=powerby>Built with <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a><br>Theme <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=2.2.0>Stack</a></b> designed by <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a></section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)"></button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.css integrity="sha256-c0uckgykQ9v5k+IqViZOZKc47Jn7KQil4/MP3ySA3F8=" crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.css integrity="sha256-SBLU4vv6CA6lHsZ1XyTdhyjJxCjPif/TRkjnsyGAGnE=" crossorigin=anonymous></main></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.5/dist/vibrant.min.js integrity="sha256-5NovOZc4iwiAWTYIFiIM7DxKUXKWvpVEuMEPLzcm5/g=" crossorigin=anonymous defer></script><script type=text/javascript src=/ts/main.js defer></script><script>(function(){const a=document.createElement('link');a.href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap",a.type="text/css",a.rel="stylesheet",document.head.appendChild(a)})()</script></body></html>